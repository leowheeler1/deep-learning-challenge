{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8a9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn = tf.keras.models.Sequential()\n",
    "        # Define Model\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        # Allow model to choose activation mode\n",
    "    nn.add( # add the first layer\n",
    "        tf.keras.layers.Dense(\n",
    "            units=hp.Int('first_units', min_value=10, max_value=100),\n",
    "            activation=activation,\n",
    "            input_dim=44\n",
    "            )\n",
    "        )\n",
    "    # I am going to let keras decide how many layers the model should have\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        nn.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), min_value=10, max_value=100),\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    nn.add( # add the output layer\n",
    "        tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation='sigmoid'\n",
    "        )\n",
    "    )\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        # compile the model\n",
    "    return nn # output the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a19ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner2 = kt.Hyperband(\n",
    "    create_model, objective=\"val_accuracy\", max_epochs=100, hyperband_iterations=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b25265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_dat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c22e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['IS_SUCCESSFUL'] # target\n",
    "X = df.drop('IS_SUCCESSFUL', axis=1) # features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) # split it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a02a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382ea989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 508 Complete [00h 01m 35s]\n",
      "val_accuracy: 0.7306122183799744\n",
      "\n",
      "Best val_accuracy So Far: 0.7341107726097107\n",
      "Total elapsed time: 02h 03m 40s\n"
     ]
    }
   ],
   "source": [
    "tuner2.search(\n",
    "    X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b855136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'first_units': 40, 'num_layers': 2, 'units_0': 11, 'units_1': 13, 'units_2': 39, 'units_3': 43, 'units_4': 18, 'tuner/epochs': 34, 'tuner/initial_epoch': 12, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0194'}\n",
      "{'activation': 'relu', 'first_units': 100, 'num_layers': 2, 'units_0': 52, 'units_1': 96, 'units_2': 81, 'units_3': 43, 'units_4': 10, 'tuner/epochs': 4, 'tuner/initial_epoch': 0, 'tuner/bracket': 3, 'tuner/round': 0}\n",
      "{'activation': 'relu', 'first_units': 60, 'num_layers': 2, 'units_0': 93, 'units_1': 86, 'units_2': 90, 'units_3': 61, 'units_4': 62, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0459'}\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner2.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9247d98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Leo\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 2ms/step - accuracy: 0.7341 - loss: 0.5510\n",
      "Loss: 0.5510062575340271, Accuracy: 0.7341107726097107\n",
      "268/268 - 0s - 1ms/step - accuracy: 0.7336 - loss: 0.5536\n",
      "Loss: 0.553550660610199, Accuracy: 0.7336443066596985\n",
      "268/268 - 0s - 1ms/step - accuracy: 0.7333 - loss: 0.5501\n",
      "Loss: 0.5500675439834595, Accuracy: 0.7332944869995117\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner2.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12555757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(hp):\n",
    "    nn = tf.keras.models.Sequential()\n",
    "        # Define Model\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        # Allow model to choose activation mode\n",
    "    nn.add( # add the first layer\n",
    "        tf.keras.layers.Dense(\n",
    "            units=hp.Int('first_units', min_value=10, max_value=100),\n",
    "            activation=activation,\n",
    "            input_dim=44\n",
    "            )\n",
    "        )\n",
    "    # I am going to let keras decide how many layers the model should have\n",
    "    for i in range(hp.Int(\"num_layers\", 2, 7)):\n",
    "        nn.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), min_value=10, max_value=100),\n",
    "                activation=activation\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    nn.add( # add the output layer\n",
    "        tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation='sigmoid'\n",
    "        )\n",
    "    )\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        # compile the model\n",
    "    return nn # output the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5d500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tuner3 = kt.Hyperband(\n",
    "    create_model2, objective=\"val_accuracy\", max_epochs=100, hyperband_iterations=2, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a7a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 500 Complete [00h 01m 48s]\n",
      "val_accuracy: 0.7315452098846436\n",
      "\n",
      "Best val_accuracy So Far: 0.7343440055847168\n",
      "Total elapsed time: 02h 19m 47s\n"
     ]
    }
   ],
   "source": [
    "tuner3.search(\n",
    "    X_train_scaled, y_train, epochs=10,validation_data=(X_test_scaled, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7185262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'first_units': 34, 'num_layers': 3, 'units_0': 78, 'units_1': 21, 'units_2': 15, 'units_3': 70, 'units_4': 87, 'units_5': 99, 'units_6': 26, 'tuner/epochs': 34, 'tuner/initial_epoch': 12, 'tuner/bracket': 4, 'tuner/round': 3, 'tuner/trial_id': '0383'}\n",
      "{'activation': 'relu', 'first_units': 34, 'num_layers': 3, 'units_0': 78, 'units_1': 21, 'units_2': 15, 'units_3': 70, 'units_4': 87, 'units_5': 99, 'units_6': 26, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 4, 'tuner/round': 4, 'tuner/trial_id': '0388'}\n",
      "{'activation': 'tanh', 'first_units': 68, 'num_layers': 5, 'units_0': 21, 'units_1': 32, 'units_2': 84, 'units_3': 16, 'units_4': 19, 'units_5': 45, 'units_6': 71, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0196'}\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner3.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42065ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Leo\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "c:\\Users\\Leo\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 1ms/step - accuracy: 0.7343 - loss: 0.5504\n",
      "Loss: 0.5504232048988342, Accuracy: 0.7343440055847168\n",
      "268/268 - 0s - 1ms/step - accuracy: 0.7332 - loss: 0.5534\n",
      "Loss: 0.5534474849700928, Accuracy: 0.7331778407096863\n",
      "268/268 - 0s - 1ms/step - accuracy: 0.7331 - loss: 0.5523\n",
      "Loss: 0.5523414015769958, Accuracy: 0.7330612540245056\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner3.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b981c",
   "metadata": {},
   "source": [
    "## Best Model Acheived:\n",
    "\n",
    "[`untitled_project/trial_0383/build_config.json`](untitled_project/trial_0383/build_config.json) <-- Input Shape\n",
    "[`untitled_project/trial_0383/trial.json`](untitled_project/trial_0383/trial.json) <-- Parameters\n",
    "\n",
    "\"values\": \n",
    "\n",
    "        {\"activation\": \"relu\",\n",
    "        \"first_units\": 34,\n",
    "        \"num_layers\": 3,\n",
    "        \"units_0\": 78,\n",
    "        \"units_1\": 21,\n",
    "        \"units_2\": 15,\n",
    "        \"tuner/epochs\": 12,\n",
    "        \"tuner/initial_epoch\": 4,\n",
    "        \"tuner/bracket\": 4,\n",
    "        \"tuner/round\": 2,\n",
    "        \"tuner/trial_id\": \"0375\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
